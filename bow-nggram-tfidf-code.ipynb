{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOW example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary        allowed  and  antagonistic  are  cats  dogs  not\n",
      "document1 vector        1    1             0    1     1     1    1\n",
      "document2 vector        0    1             1    1     1     1    0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = ['Cats and dogs are not allowed', 'Cats and dogs are antagonistic']\n",
    "count_vect = CountVectorizer()\n",
    "X = count_vect.fit_transform(corpus)\n",
    "X\n",
    "\n",
    "import pandas as pd\n",
    " \n",
    "df = pd.DataFrame()\n",
    "df['vocabulary'] = count_vect.get_feature_names()\n",
    "df['document1 vector'] = X.toarray()[0]\n",
    "df['document2 vector'] = X.toarray()[1]\n",
    "df.set_index('vocabulary', inplace=True)\n",
    "print(df.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF_IDF Example\n",
    "tf = (no of times words appear in a doc)/(totoal no of words in the doc)\n",
    "IDF - IDF measures of importance of word, taking into consideration the frequency of the word through out the corpus\n",
    "idf = log(total no of docs/no of docs with the word in it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary       and  antagonistic       are      cats      dogs      four  \\\n",
      "sentence1   0.000000      0.000000  0.000000  0.402040  0.000000  0.528635   \n",
      "sentence2   0.490479      0.490479  0.490479  0.373022  0.373022  0.000000   \n",
      "sentence3   0.000000      0.000000  0.000000  0.000000  0.473630  0.000000   \n",
      "\n",
      "vocabulary      hate      have        he      legs  \n",
      "sentence1   0.000000  0.528635  0.000000  0.528635  \n",
      "sentence2   0.000000  0.000000  0.000000  0.000000  \n",
      "sentence3   0.622766  0.000000  0.622766  0.000000  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    " \n",
    "corpus = ['Cats have four legs',\n",
    "          'Cats and dogs are antagonistic',\n",
    "          'He hate dogs']\n",
    "tfidf = TfidfVectorizer()\n",
    "vect = tfidf.fit_transform(corpus)\n",
    " \n",
    "df = pd.DataFrame()\n",
    "df['vocabulary'] = tfidf.get_feature_names()\n",
    "df['sentence1'] = vect.toarray()[0]\n",
    "df['sentence2'] = vect.toarray()[1]\n",
    "df['sentence3'] = vect.toarray()[2]\n",
    "df.set_index('vocabulary', inplace=True)\n",
    "print(df.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ng-gram example\n",
    "An N-Gram is a sequence of N-words in a sentence. Here, N is an integer which stands for the number of words in the sequence.\n",
    "\n",
    "For example, if we put N=1, then it is referred to as a uni-gram. If you put N=2, then it is a bi-gram. If we substitute N=3, then it is a tri-gram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I', 'like')\n",
      "('like', 'dancing')\n",
      "('dancing', 'in')\n",
      "('in', 'the')\n",
      "('the', 'rain')\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "sentence = 'I like dancing in the rain'\n",
    "ngram = ngrams(sentence.split(' '),n=2)\n",
    "for x in ngram:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
